{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "import os\n",
    "import itertools\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import math\n",
    "from typing import List\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import dgl\n",
    "import torch\n",
    "from typing import Tuple\n",
    "import torch.nn.functional as torch_f\n",
    "import tqdm\n",
    "import torch.nn as nn\n",
    "import dgl.function as fn\n",
    "\n",
    "from src.utils import fit_lr_classifier, infer_lr_classifier, calculate_score, calculate_score_raw\n",
    "from src.utils import generate_submission\n",
    "from src.utils import dump_features\n",
    "from src.models import GraphSAGEBundled\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "device = torch.device('cuda:2') if torch.cuda.is_available() else torch.device('cpu')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Voter:\n",
    "    def __init__(self, estimators: list, weight=None):\n",
    "        self.estimators_lookup = {name: idx for idx, (name, _) in enumerate(estimators)}\n",
    "        self.estimators = [item for name, item in estimators]\n",
    "        if weight is not None:\n",
    "            self.weight = weight / sum(weight)\n",
    "        else:\n",
    "            self.weight = None\n",
    "\n",
    "    def fit(self, x, y, *args, **kwargs):\n",
    "        for name, data in x.keys():\n",
    "            self.estimators[self.estimators_lookup[name]].fit(data, y, *args, **kwargs)\n",
    "            print(f\"fitting: {name}\")\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        predictions = [self.estimators[self.estimators_lookup[name]].predict_proba(x[name]) for name in x.keys()]\n",
    "        summary = 0\n",
    "\n",
    "        for idx, partial_result in enumerate(predictions):\n",
    "            if self.weight is not None:\n",
    "                summary += partial_result * self.weight[idx]\n",
    "            else:\n",
    "                summary += 1 / len(self.estimators) * partial_result\n",
    "\n",
    "        return summary\n",
    "\n",
    "    def decide(self, x, thresh=0.5):\n",
    "        predictions = [self.estimators[self.estimators_lookup[name]].predict_proba(x[name]) for name in x.keys()]\n",
    "        summary = 0\n",
    "\n",
    "        for idx, partial_result in enumerate(predictions):\n",
    "            if self.weight is not None:\n",
    "                summary += partial_result * self.weight[idx]\n",
    "            else:\n",
    "                summary += 1 / len(self.estimators) * partial_result\n",
    "\n",
    "        return summary[:, 1] > 0.5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features = {\n",
    "    'author_graph_lr': pickle.load(open('./features/author_graph_lr_features.pkl', 'rb')),\n",
    "    'graphsage_author': pickle.load(open('./features/graphsage_author_features.pkl', 'rb')),\n",
    "    'graphsage_essay': pickle.load(open('./features/graphsage_essay_features.pkl', 'rb')),\n",
    "    'baseline_enhanced': pickle.load(open('./features/baseline-enhanced.pkl','rb'))\n",
    "}\n",
    "uv_list = pickle.load(open('./uv_list.pkl', 'rb'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# X_train_1 = np.concatenate([features['graphsage_author']['X_train'], features['graphsage_essay']['X_train']], axis=1)\n",
    "# X_dev_1 = np.concatenate([features['graphsage_author']['X_dev'], features['graphsage_essay']['X_dev']], axis=1)\n",
    "# X_test_1 =  np.concatenate([features['graphsage_author']['X_test'], features['graphsage_essay']['X_test']], axis=1)\n",
    "X_train_0 = features['baseline_enhanced']['X_train']\n",
    "X_dev_0 = features['baseline_enhanced']['X_dev']\n",
    "X_test_0 =  features['baseline_enhanced']['X_test']\n",
    "X_whole_0 = np.concatenate([features['baseline_enhanced']['X_train'],\n",
    "                            features['baseline_enhanced']['X_dev']],axis=0)\n",
    "\n",
    "X_train_1 = features['graphsage_essay']['X_train']\n",
    "X_dev_1 = features['graphsage_essay']['X_dev']\n",
    "X_test_1 =  features['graphsage_essay']['X_test']\n",
    "X_whole_1 = np.concatenate([features['graphsage_essay']['X_train'],\n",
    "                            features['graphsage_essay']['X_dev']],axis=0)\n",
    "\n",
    "\n",
    "X_train_2 = features['author_graph_lr']['X_train']\n",
    "X_dev_2 = features['author_graph_lr']['X_dev']\n",
    "X_test_2 = features['author_graph_lr']['X_test']\n",
    "X_whole_2 = np.concatenate([features['author_graph_lr']['X_train'],\n",
    "                            features['author_graph_lr']['X_dev']],axis=0)\n",
    "\n",
    "Y_train = uv_list['train_y']\n",
    "Y_dev = uv_list['dev_y']\n",
    "Y_whole = np.concatenate([Y_train, Y_dev], axis=0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clf0 = fit_lr_classifier(\n",
    "    X_train_0,\n",
    "    Y_train,\n",
    "    X_dev_0,\n",
    "    Y_dev,\n",
    "    solver='lbfgs',\n",
    "    tol=1e-5,\n",
    "    max_iter=1000,\n",
    "    n_jobs=12,\n",
    "    verbose=1,\n",
    ")  # weight = 0.9\n",
    "clf1 = fit_lr_classifier(X_train_1, Y_train, X_dev_1, Y_dev, max_iter=400, n_jobs=12)  # weight = 0.9\n",
    "clf2 = fit_lr_classifier(X_train_2, Y_train, X_dev_2, Y_dev, max_iter=400, n_jobs=12)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clf0 = fit_lr_classifier(\n",
    "    X_whole_0,\n",
    "    Y_whole,\n",
    "    X_dev_0,\n",
    "    Y_dev,\n",
    "    solver='lbfgs',\n",
    "    tol=1e-5,\n",
    "    max_iter=1000,\n",
    "    n_jobs=8,\n",
    "    verbose=1,\n",
    ")  # weight = 0.9\n",
    "clf1 = fit_lr_classifier(\n",
    "    X_whole_1,\n",
    "    Y_whole,\n",
    "    X_dev_1,\n",
    "    Y_dev,\n",
    "    tol=1e-5,\n",
    "    max_iter=600,\n",
    "    verbose=1,\n",
    ")  # weight = 0.9\n",
    "clf2 = fit_lr_classifier(\n",
    "    X_whole_2, \n",
    "    Y_whole, \n",
    "    X_dev_2, \n",
    "    Y_dev, \n",
    "    tol=1e-5,\n",
    "    max_iter=600, \n",
    "    verbose=1,\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "voter = Voter(estimators=[('lr0', clf0), ('lr1', clf1), ('lr2', clf2)],weight=np.array([100,87,88]))\n",
    "calculate_score(voter, {'lr0': X_dev_0, 'lr1': X_dev_1, 'lr2': X_dev_2}, Y_dev)\n",
    "\n",
    "scores = infer_lr_classifier(voter, {'lr0': X_test_0, 'lr1': X_test_1, 'lr2': X_test_2})\n",
    "generate_submission('./outputs', scores, \"soft_voting\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred = voter.decide({'lr0': X_dev_0, 'lr1': X_dev_1, 'lr2': X_dev_2})\n",
    "calculate_score_raw(pred, Y_dev)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "uv_list = pickle.load(open('./uv_list.pkl', 'rb'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sum(uv_list['train_'] - features['baseline_enhanced']['train_u'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train_3 = np.concatenate([X_train_0, X_train_2], axis=1)\n",
    "X_dev_3 = np.concatenate([X_dev_0, X_dev_2], axis=1)\n",
    "X_test_3 =  np.concatenate([X_test_0, X_test_2], axis=1)\n",
    "X_whole_3 =  np.concatenate([X_whole_0, X_whole_2], axis=1)\n",
    "\n",
    "clf3 = fit_lr_classifier(\n",
    "    X_whole_3,\n",
    "    Y_whole,\n",
    "    X_dev_3,\n",
    "    Y_dev,\n",
    "    solver='lbfgs',\n",
    "    tol=1e-5,\n",
    "    max_iter=1000,\n",
    "    n_jobs=8,\n",
    "    verbose=1,\n",
    ")  # weight = 0.9"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scores = infer_lr_classifier(clf3, X_test_3)\n",
    "generate_submission('./outputs', scores, \"all_gather\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "uv_list = pickle.load(open('./uv_list.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(uv_list['train_'] - features['baseline_enhanced']['train_u'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =           22     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.51377D+06    |proj g|=  4.39656D+08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f=  8.46908D+05    |proj g|=  5.99474D+06\n",
      "\n",
      "At iterate  100    f=  6.99621D+05    |proj g|=  2.00496D+06\n",
      "\n",
      "At iterate  150    f=  6.78824D+05    |proj g|=  8.03980D+06\n",
      "\n",
      "At iterate  200    f=  5.11588D+05    |proj g|=  1.68195D+05\n",
      "\n",
      "At iterate  250    f=  5.07812D+05    |proj g|=  2.27037D+07\n",
      "\n",
      "At iterate  300    f=  4.96959D+05    |proj g|=  6.22148D+06\n",
      "\n",
      "At iterate  350    f=  3.90439D+05    |proj g|=  2.16010D+06\n",
      "\n",
      "At iterate  400    f=  3.84732D+05    |proj g|=  4.56389D+06\n",
      "\n",
      "At iterate  450    f=  3.73698D+05    |proj g|=  2.59223D+06\n",
      "\n",
      "At iterate  500    f=  3.48914D+05    |proj g|=  1.15768D+06\n",
      "\n",
      "At iterate  550    f=  3.48515D+05    |proj g|=  2.14345D+06\n",
      "\n",
      "At iterate  600    f=  3.46434D+05    |proj g|=  6.39619D+06\n",
      "\n",
      "At iterate  650    f=  3.15244D+05    |proj g|=  1.69585D+06\n",
      "\n",
      "At iterate  700    f=  3.15006D+05    |proj g|=  6.81987D+04\n",
      "\n",
      "At iterate  750    f=  3.14909D+05    |proj g|=  1.41830D+05\n",
      "\n",
      "At iterate  800    f=  3.14865D+05    |proj g|=  4.05193D+05\n",
      "\n",
      "At iterate  850    f=  3.14554D+05    |proj g|=  6.05778D+05\n",
      "\n",
      "At iterate  900    f=  3.14222D+05    |proj g|=  1.49680D+05\n",
      "\n",
      "At iterate  950    f=  3.14184D+05    |proj g|=  1.71937D+05\n",
      "\n",
      "At iterate 1000    f=  3.14161D+05    |proj g|=  1.03830D+05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "   22   1000   1111      1     0     0   1.038D+05   3.142D+05\n",
      "  F =   314160.50872960693     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/imu/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=12)]: Done   1 out of   1 | elapsed:  7.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.14133211323101885, Accuracy: 0.9428112880109528, F1-score: 0.9417685990101665\n"
     ]
    }
   ],
   "source": [
    "X_train_3 = np.concatenate([X_train_0, X_train_2], axis=1)\n",
    "X_dev_3 = np.concatenate([X_dev_0, X_dev_2], axis=1)\n",
    "X_test_3 =  np.concatenate([X_test_0, X_test_2], axis=1)\n",
    "X_whole_3 =  np.concatenate([X_whole_0, X_whole_2], axis=1)\n",
    "\n",
    "clf3 = fit_lr_classifier(\n",
    "    X_whole_3,\n",
    "    Y_whole,\n",
    "    X_dev_3,\n",
    "    Y_dev,\n",
    "    solver='lbfgs',\n",
    "    tol=1e-5,\n",
    "    max_iter=1000,\n",
    "    n_jobs=8,\n",
    "    verbose=1,\n",
    ")  # weight = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "107000.0it [00:00, 1236593.04it/s]        \n"
     ]
    }
   ],
   "source": [
    "scores = infer_lr_classifier(clf3, X_test_3)\n",
    "generate_submission('./outputs', scores, \"all_gather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}